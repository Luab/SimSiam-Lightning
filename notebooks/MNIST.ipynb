{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- Full use of PyTorch Lightning project template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malkalait\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    }
   ],
   "source": [
    "## Regular imports\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "## Lightning imports\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import Callback, LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "## PyTorch imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "print(f'Cuda available: {torch.cuda.is_available()}')\n",
    "\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "## Internal imports\n",
    "from src.callbacks import ImagePredictionLogger\n",
    "from src.dataset import ComposeMany, ComposeManyTorch, MNISTDataModule2\n",
    "from src.losses import log_softmax, simsiam_loss\n",
    "from src.models import accuracy, feature_std, CNN, BaseLitModel, SimSiam\n",
    "from src.utils import sweep_iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentator\n",
    "\n",
    "AUG_KWARGS = dict(border_mode=A.cv2.BORDER_CONSTANT, value=0,\n",
    "                  interpolation=A.cv2.INTER_LANCZOS4)\n",
    "\n",
    "train_transforms = ComposeMany([\n",
    "    #A.RandomCrop(width=24, height=24),\n",
    "    #A.HorizontalFlip(p=0.5),\n",
    "    #A.GridDistortion(p=0.5, distort_limit=.3, **AUG_KWARGS),\n",
    "    A.ElasticTransform(p=0.5, sigma=1, alpha=3, alpha_affine=0, **AUG_KWARGS),\n",
    "    A.ElasticTransform(p=0.5, sigma=1, alpha=1, alpha_affine=3, **AUG_KWARGS),\n",
    "    A.ShiftScaleRotate(p=1.0, scale_limit=.2, rotate_limit=0, **AUG_KWARGS),\n",
    "    A.ShiftScaleRotate(p=1.0, scale_limit=0, rotate_limit=25, **AUG_KWARGS),\n",
    "    #A.CoarseDropout(p=1.0, max_holes=8, max_height=4, max_width=4,\n",
    "    #                min_holes=1, min_height=4, min_width=4),\n",
    "    #A.RandomBrightnessContrast(p=0.2),\n",
    "    #A.Blur(blur_limit=4),\n",
    "    A.Normalize(mean=(0.0,), std=(1,)),  # , max_pixel_value=255),\n",
    "    ToTensorV2()\n",
    "], n_aug=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lightning datamodule. Comes with its own train / val / test dataloader.\n",
    "mnist = MNISTDataModule2(data_dir='../data/', batch_size=512, train_transforms=train_transforms)\n",
    "mnist.prepare_data()\n",
    "mnist.setup()\n",
    "\n",
    "## Backbone arch\n",
    "cnn = CNN(num_channels=mnist.dims[0], num_classes=mnist.num_classes,\n",
    "          wpool=7, maxpool=False)\n",
    "\n",
    "## Metrics: (name of log-entry, metric)\n",
    "metrics = (('acc', accuracy),)\n",
    "\n",
    "model = BaseLitModel(\n",
    "    datamodule=mnist, backbone=cnn, loss_func=log_softmax, metrics=metrics,\n",
    "    lr=1e-3, flood_height=0.03\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger = WandbLogger(project='SimSiam-Lightning', job_type='train')\n",
    "callbacks = [\n",
    "    LearningRateMonitor(),  # log the LR\n",
    "    ModelCheckpoint(monitor='val_loss'),\n",
    "    ImagePredictionLogger(mnist.val_dataloader(batch_size=32), n_samples=32),\n",
    "]\n",
    "\n",
    "trainer = Trainer(\n",
    "    weights_summary='full',\n",
    "    max_epochs=200, gpus=-1,  # all GPUs\n",
    "    logger=wandb_logger, callbacks=callbacks,\n",
    "    accumulate_grad_batches=1, gradient_clip_val=0,  # 0.5\n",
    "    progress_bar_refresh_rate=20,\n",
    "    #fast_dev_run=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.fit(model, mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimSiam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Augmentator\n",
    "AUG_KWARGS = dict(border_mode=A.cv2.BORDER_CONSTANT, value=0,\n",
    "                  interpolation=A.cv2.INTER_LANCZOS4)\n",
    "transforms = ComposeMany([\n",
    "    #A.ElasticTransform(p=0.5, sigma=1, alpha=3, alpha_affine=0, **AUG_KWARGS),\n",
    "    #A.ElasticTransform(p=0.5, sigma=1, alpha=1, alpha_affine=3, **AUG_KWARGS),\n",
    "    A.ShiftScaleRotate(p=1.0, scale_limit=.2, rotate_limit=0, **AUG_KWARGS),\n",
    "    A.ShiftScaleRotate(p=1.0, scale_limit=0, rotate_limit=10, **AUG_KWARGS),\n",
    "    A.Normalize(mean=(0.0,), std=(1,)),  # , max_pixel_value=255),\n",
    "    ToTensorV2()\n",
    "], n_aug=2)\n",
    "\n",
    "# transforms = ComposeManyTorch([\n",
    "#     T.RandomResizedCrop(28, scale=(0.6, 1.0)),\n",
    "#     #T.RandomHorizontalFlip(),\n",
    "#     T.RandomApply([T.ColorJitter(0.4,0.4,0.4,0.1)], p=0.8),\n",
    "#     #T.RandomGrayscale(p=0.2),\n",
    "#     T.RandomApply([T.GaussianBlur(kernel_size=28//20*2+1, sigma=(0.1, 2.0))], p=0.5),\n",
    "#     T.ToTensor(),\n",
    "#     T.Normalize([0.1307], [0.3081]),\n",
    "# ], n_aug=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging metrics: ['featstd']\n"
     ]
    }
   ],
   "source": [
    "## Lightning datamodule. Comes with its own train / val / test dataloader.\n",
    "mnist = MNISTDataModule2(data_dir='../data/',\n",
    "                         batch_size=128,\n",
    "                         train_transforms=transforms,\n",
    "                         val_transforms=transforms)\n",
    "mnist.prepare_data(); mnist.setup()\n",
    "\n",
    "## Backbone arch\n",
    "cnn = CNN(num_channels=mnist.dims[0], num_classes=mnist.num_classes,\n",
    "          maxpool=False, wpool=5, p_dropout=0.0)\n",
    "simsiam = SimSiam(backbone=cnn, p_dropout=0.0)\n",
    "\n",
    "model = BaseLitModel(\n",
    "    datamodule=mnist, backbone=simsiam,\n",
    "    loss_func=simsiam_loss,\n",
    "    metrics=(('featstd', feature_std),),\n",
    "    lr=0.05 * mnist.train_dataloader().batch_size / 256,\n",
    "    #flood_height=0.03\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "wandb_logger = WandbLogger(project='SimSiam-Lightning', job_type='train')\n",
    "callbacks = [\n",
    "    LearningRateMonitor(),  # log the LR\n",
    "    ModelCheckpoint(monitor='val_loss'),\n",
    "    #ImagePredictionLogger(mnist.val_dataloader(batch_size=32), n_samples=32),\n",
    "]\n",
    "\n",
    "trainer = Trainer(\n",
    "    weights_summary='full',\n",
    "    max_epochs=100, gpus=-1,  # all GPUs\n",
    "    logger=wandb_logger, callbacks=callbacks,\n",
    "    accumulate_grad_batches=1, gradient_clip_val=0,  # 0.5\n",
    "    progress_bar_refresh_rate=20,\n",
    "    #fast_dev_run=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging metrics: ['featstd']\n"
     ]
    }
   ],
   "source": [
    "path = ('/home/freddie/projects/SimSiam-Lightning/notebooks/'\n",
    "        'SimSiam-Lightning/2gow693t/checkpoints/epoch=136-step=58772.ckpt')\n",
    "model = model.load_from_checkpoint(checkpoint_path=path)\n",
    "model = model.to('cuda')\n",
    "# model.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-NN monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code copied from\n",
    "\n",
    "- https://colab.research.google.com/github/facebookresearch/moco/blob/colab-notebook/colab/moco_cifar10_demo.ipynb#scrollTo=J4YUQeIvuuMd\n",
    "- http://github.com/zhirongw/lemniscate.pytorch\n",
    "- https://github.com/leftthomas/SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = ComposeMany([A.Normalize(mean=(0.0,), std=(1,)), ToTensorV2()])\n",
    "memory_dataloader = mnist.train_dataloader(transforms=test_transforms)\n",
    "test_dataloader = mnist.test_dataloader(transforms=test_transforms)\n",
    "\n",
    "knn_monitor(model.backbone.f, memory_dataloader, test_dataloader,\n",
    "            knn_k=10, device=model.device, epoch=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = model.device\n",
    "model.eval()\n",
    "classes = len(memory_dataloader.dataset.dataset.classes)\n",
    "total_top1, total_top5, total_num, feature_bank = 0.0, 0.0, 0, []\n",
    "\n",
    "with torch.no_grad():\n",
    "    ## Generate feature bank.\n",
    "    for data, _ in tqdm(memory_dataloader, desc='Feature extracting'):\n",
    "        feature = model.backbone.f(data.to(device))\n",
    "        feature = F.normalize(feature, dim=1)\n",
    "        feature_bank.append(feature)\n",
    "    ## [D, N]\n",
    "    feature_bank = torch.cat(feature_bank, dim=0).t().contiguous()\n",
    "    ## [N]\n",
    "    feature_labels = memory_dataloader.dataset.dataset.targets.to(feature_bank.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = next(iter(test_dataloader))\n",
    "data, target = data.to(device), target.to(device)\n",
    "feature = model.backbone.f(data)\n",
    "feature = F.normalize(feature, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_bank.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_predict(feature=feature, feature_bank=feature_bank, feature_labels=feature_labels,\n",
    "            classes=classes, knn_k=200, knn_t=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor([[1,2,3,4,5]]).to(int).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor([1,2,3,4,5]).to(int).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_predict(feature=torch.Tensor([[1,0,0,0,0]]), feature_bank=torch.eye(5),\n",
    "            feature_labels=torch.Tensor([1,2,3,4,5]).to(int), classes=5, knn_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def knn_monitor(model, memory_dataloader, test_dataloader,\n",
    "                device, epoch, knn_k, knn_t=1, epochs=''):\n",
    "    '''Test using a k-nn monitor.'''\n",
    "\n",
    "    model.eval()\n",
    "    classes = len(memory_dataloader.dataset.dataset.classes)\n",
    "    total_top1, total_top5, total_num, feature_bank = 0.0, 0.0, 0, []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ## Generate feature bank.\n",
    "        for data, _ in tqdm(memory_dataloader, desc='Feature extracting'):\n",
    "            feature = model(data.to(device))\n",
    "            feature = F.normalize(feature, dim=1)\n",
    "            feature_bank.append(feature)\n",
    "        ## [D, N]\n",
    "        feature_bank = torch.cat(feature_bank, dim=0).t().contiguous()\n",
    "        ## [N]\n",
    "        feature_labels = memory_dataloader.dataset.dataset.targets.to(feature_bank.device)\n",
    "        ## Loop test data to predict the label by weighted knn search.\n",
    "        test_bar = tqdm(test_dataloader)\n",
    "        for data, target in test_bar:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            feature = model(data)\n",
    "            feature = F.normalize(feature, dim=1)\n",
    "            pred_labels = knn_predict(feature, feature_bank, feature_labels,\n",
    "                                      classes, knn_k, knn_t)\n",
    "            total_num += data.size(0)\n",
    "            total_top1 += (pred_labels[:, 0] == target).float().sum().item()\n",
    "            test_bar.set_description(\n",
    "                'Test Epoch: [{}/{}] Acc@1:{:.2f}%'.format(\n",
    "                    epoch, epochs, total_top1 / total_num * 100\n",
    "                )\n",
    "            )\n",
    "    return total_top1 / total_num * 100\n",
    "\n",
    "\n",
    "def knn_predict(feature, feature_bank, feature_labels, classes, knn_k, knn_t=1):\n",
    "    '''\n",
    "    k-NN monitor as in InstDisc https://arxiv.org/abs/1805.01978\n",
    "    Implementation follows http://github.com/zhirongw/lemniscate.pytorch\n",
    "    and https://github.com/leftthomas/SimCLR\n",
    "    '''\n",
    "    ## Cos similarity between each feature vector and feature bank ---> [B, N]\n",
    "    sim_matrix = torch.mm(feature, feature_bank)\n",
    "    ## [B, K]\n",
    "    sim_weight, sim_indices = sim_matrix.topk(k=knn_k, dim=-1)\n",
    "    ## [B, K]\n",
    "    sim_labels = torch.gather(feature_labels.expand(feature.size(0), -1),\n",
    "                              dim=-1, index=sim_indices)\n",
    "    sim_weight = (sim_weight / knn_t).exp()\n",
    "\n",
    "    ## Counts for each class\n",
    "    one_hot_label = torch.zeros(feature.size(0) * knn_k, classes, device=sim_labels.device)\n",
    "    ## [B*K, C]\n",
    "    one_hot_label = one_hot_label.scatter(dim=-1, index=sim_labels.view(-1, 1), value=1.0)\n",
    "    ## Weighted score ---> [B, C]\n",
    "    pred_scores = torch.sum(\n",
    "        one_hot_label.view(feature.size(0), -1, classes) * sim_weight.unsqueeze(dim=-1),\n",
    "        dim=1\n",
    "    )\n",
    "    pred_labels = pred_scores.argsort(dim=-1, descending=True)\n",
    "    return pred_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
