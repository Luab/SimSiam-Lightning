{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# regular imports\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Lightning import\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import Callback, LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pl_bolts.datamodules.mnist_datamodule import MNISTDataModule\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "print(f'Cuda available: {torch.cuda.is_available()}')\n",
    "\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "# internal imports\n",
    "from src.callbacks import ImagePredictionLogger\n",
    "from src.dataset import ComposeMany  # , alb_to_torch_aug, MNISTDataModule\n",
    "from src.losses import log_softmax, simsiam_loss\n",
    "from src.models import accuracy, CNN, BaseLitModel, SimSiam\n",
    "from src.utils import sweep_iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentator\n",
    "\n",
    "AUG_KWARGS = dict(border_mode=A.cv2.BORDER_CONSTANT, value=0,\n",
    "                  interpolation=A.cv2.INTER_LANCZOS4)\n",
    "\n",
    "train_transforms = ComposeMany([\n",
    "    #A.RandomCrop(width=24, height=24),\n",
    "    #A.HorizontalFlip(p=0.5),\n",
    "    #A.GridDistortion(p=0.5, distort_limit=.3, **AUG_KWARGS),\n",
    "    A.ElasticTransform(p=0.5, sigma=1, alpha=3, alpha_affine=0, **AUG_KWARGS),\n",
    "    A.ElasticTransform(p=0.5, sigma=1, alpha=1, alpha_affine=3, **AUG_KWARGS),\n",
    "    A.ShiftScaleRotate(p=1.0, scale_limit=.2, rotate_limit=0, **AUG_KWARGS),\n",
    "    A.ShiftScaleRotate(p=1.0, scale_limit=0, rotate_limit=25, **AUG_KWARGS),\n",
    "    #A.CoarseDropout(p=1.0, max_holes=8, max_height=4, max_width=4,\n",
    "    #                min_holes=1, min_height=4, min_width=4),\n",
    "    #A.RandomBrightnessContrast(p=0.2),\n",
    "    #A.Blur(blur_limit=4),\n",
    "    A.Normalize(mean=(0.0,), std=(1,)),  # , max_pixel_value=255),\n",
    "    ToTensorV2()\n",
    "], n_aug=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "proj = 'SimSiam-Lightning'\n",
    "\n",
    "## Lightning datamodule. Comes with its own train / val / test dataloader.\n",
    "mnist = MNISTDataModule('../data/', batch_size=512, train_transforms=train_transforms)\n",
    "mnist.prepare_data()\n",
    "mnist.setup()\n",
    "\n",
    "## Backbone arch\n",
    "cnn = CNN(num_channels=mnist.dims[0], num_classes=mnist.num_classes)\n",
    "\n",
    "## Metrics: (name of log-entry, metric)\n",
    "metrics = (('acc', accuracy),)\n",
    "\n",
    "model = BaseLitModel(\n",
    "    datamodule=mnist, backbone=cnn, loss_func=log_softmax, metrics=metrics,\n",
    "    lr=1e-3, flood_height=0.03\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger = WandbLogger(project=proj, job_type='train')\n",
    "callbacks = [\n",
    "    LearningRateMonitor(),  # log the LR\n",
    "    ImagePredictionLogger(mnist.val_dataloader(batch_size=32), n_samples=32),\n",
    "]\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=200, gpus=-1,  # all GPUs\n",
    "    logger=wandb_logger, callbacks=callbacks,\n",
    "    accumulate_grad_batches=1, gradient_clip_val=0,  # 0.5\n",
    "    progress_bar_refresh_rate=20,\n",
    "    fast_dev_run=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.fit(model, mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# LR finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Learning rate finder\n",
    "# lr_finder = trainer.tuner.lr_find(model, num_training=3000, mode='linear', max_lr=1e-2)\n",
    "# # lr_finder.results  # Results can be found in\n",
    "# fig = lr_finder.plot(suggest=True)\n",
    "# lr_finder.suggestion()\n",
    "# model.hparams.lr = new_lr  # update hparams of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter sweep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.sweeps import sweep_config\n",
    "\n",
    "# sweep_id = wandb.sweep(sweep_config, project=proj)\n",
    "\n",
    "# wandb.agent(sweep_id, function=sweep_iteration, project=proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# SimSiam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentator\n",
    "\n",
    "AUG_KWARGS = dict(border_mode=A.cv2.BORDER_CONSTANT, value=0,\n",
    "                  interpolation=A.cv2.INTER_LANCZOS4)\n",
    "\n",
    "transforms = ComposeMany([\n",
    "    A.ElasticTransform(p=0.5, sigma=1, alpha=3, alpha_affine=0, **AUG_KWARGS),\n",
    "    A.ElasticTransform(p=0.5, sigma=1, alpha=1, alpha_affine=3, **AUG_KWARGS),\n",
    "    A.ShiftScaleRotate(p=1.0, scale_limit=.2, rotate_limit=0, **AUG_KWARGS),\n",
    "    A.ShiftScaleRotate(p=1.0, scale_limit=0, rotate_limit=25, **AUG_KWARGS),\n",
    "    A.Normalize(mean=(0.0,), std=(1,)),  # , max_pixel_value=255),\n",
    "    ToTensorV2()\n",
    "], n_aug=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = 'SimSiam-Lightning'\n",
    "\n",
    "## Lightning datamodule. Comes with its own train / val / test dataloader.\n",
    "mnist = MNISTDataModule('../data/', batch_size=512,\n",
    "                        train_transforms=transforms, val_transforms=transforms)\n",
    "mnist.prepare_data()\n",
    "mnist.setup()\n",
    "\n",
    "## Backbone arch\n",
    "cnn = CNN(num_channels=mnist.dims[0], num_classes=mnist.num_classes)\n",
    "simsiam = SimSiam(backbone=cnn)\n",
    "\n",
    "model = BaseLitModel(\n",
    "    datamodule=mnist, backbone=simsiam, loss_func=simsiam_loss, #metrics=metrics,\n",
    "    lr=1e-3, #flood_height=0.03\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = mnist.val_dataloader(batch_size=32).dataset[0][0].numpy()\n",
    "# # tmp = mnist.val_dataloader(batch_size=32).dataset[0][0].numpy()\n",
    "# tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger = WandbLogger(project=proj, job_type='train')\n",
    "callbacks = [\n",
    "    LearningRateMonitor(),  # log the LR\n",
    "    #ImagePredictionLogger(mnist.val_dataloader(batch_size=32), n_samples=32),\n",
    "]\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=200, #gpus=-1,  # all GPUs\n",
    "    logger=wandb_logger, callbacks=callbacks,\n",
    "    accumulate_grad_batches=1, gradient_clip_val=0,  # 0.5\n",
    "    progress_bar_refresh_rate=20,\n",
    "    fast_dev_run=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, mnist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
